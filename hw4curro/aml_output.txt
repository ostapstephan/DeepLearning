Using TensorFlow backend.
2018-10-02 01:22:41.238730: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-10-02 01:22:41.312093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-02 01:22:41.312413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785
pciBusID: 0000:01:00.0
totalMemory: 3.94GiB freeMemory: 3.07GiB
2018-10-02 01:22:41.312427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2018-10-02 01:22:41.492130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-02 01:22:41.492164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2018-10-02 01:22:41.492168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2018-10-02 01:22:41.492312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2774 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0, compute capability: 5.2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     
_________________________________________________________________
activation_5 (Activation)    (None, 8, 8, 128)         0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 8, 8, 128)         512       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    
_________________________________________________________________
activation_6 (Activation)    (None, 8, 8, 128)         0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 8, 8, 128)         512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                20490     
=================================================================
Total params: 309,290
Trainable params: 308,394
Non-trainable params: 896
_________________________________________________________________
Epoch 1/125
781/781 [==============================] - 17s 22ms/step - loss: 1.8861 - acc: 0.4272 - val_loss: 1.3149 - val_acc: 0.5865
Epoch 2/125
781/781 [==============================] - 16s 20ms/step - loss: 1.2498 - acc: 0.5945 - val_loss: 1.0737 - val_acc: 0.6725
Epoch 3/125
781/781 [==============================] - 16s 20ms/step - loss: 1.0642 - acc: 0.6586 - val_loss: 0.8765 - val_acc: 0.7249
Epoch 4/125
781/781 [==============================] - 16s 20ms/step - loss: 0.9712 - acc: 0.6942 - val_loss: 0.9582 - val_acc: 0.7136
Epoch 5/125
781/781 [==============================] - 16s 20ms/step - loss: 0.9031 - acc: 0.7151 - val_loss: 0.8808 - val_acc: 0.7403
Epoch 6/125
781/781 [==============================] - 16s 20ms/step - loss: 0.8572 - acc: 0.7351 - val_loss: 0.8458 - val_acc: 0.7569
Epoch 7/125
781/781 [==============================] - 16s 20ms/step - loss: 0.8228 - acc: 0.7512 - val_loss: 0.7797 - val_acc: 0.7749
Epoch 8/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7869 - acc: 0.7643 - val_loss: 0.7130 - val_acc: 0.7965
Epoch 9/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7705 - acc: 0.7713 - val_loss: 0.7206 - val_acc: 0.7946
Epoch 10/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7545 - acc: 0.7802 - val_loss: 0.6846 - val_acc: 0.8077
Epoch 11/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7409 - acc: 0.7846 - val_loss: 0.7003 - val_acc: 0.7991
Epoch 12/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7257 - acc: 0.7896 - val_loss: 0.7369 - val_acc: 0.7937
Epoch 13/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7183 - acc: 0.7932 - val_loss: 0.6957 - val_acc: 0.8083
Epoch 14/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7082 - acc: 0.7994 - val_loss: 0.7394 - val_acc: 0.7932
Epoch 15/125
781/781 [==============================] - 16s 20ms/step - loss: 0.7011 - acc: 0.8014 - val_loss: 0.6606 - val_acc: 0.8218
Epoch 16/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6918 - acc: 0.8051 - val_loss: 0.6293 - val_acc: 0.8330
Epoch 17/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6839 - acc: 0.8080 - val_loss: 0.7020 - val_acc: 0.8113
Epoch 18/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6786 - acc: 0.8109 - val_loss: 0.6482 - val_acc: 0.8336
Epoch 19/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6700 - acc: 0.8133 - val_loss: 0.6595 - val_acc: 0.8276
Epoch 20/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6689 - acc: 0.8175 - val_loss: 0.6593 - val_acc: 0.8233
Epoch 21/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6653 - acc: 0.8190 - val_loss: 0.6246 - val_acc: 0.8356
Epoch 22/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6607 - acc: 0.8191 - val_loss: 0.6681 - val_acc: 0.8253
Epoch 23/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6540 - acc: 0.8229 - val_loss: 0.5939 - val_acc: 0.8460
Epoch 24/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6486 - acc: 0.8244 - val_loss: 0.6182 - val_acc: 0.8446
Epoch 25/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6439 - acc: 0.8258 - val_loss: 0.6467 - val_acc: 0.8346
Epoch 26/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6425 - acc: 0.8259 - val_loss: 0.6568 - val_acc: 0.8303
Epoch 27/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6392 - acc: 0.8295 - val_loss: 0.7139 - val_acc: 0.8134
Epoch 28/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6415 - acc: 0.8280 - val_loss: 0.6441 - val_acc: 0.8360
Epoch 29/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6348 - acc: 0.8296 - val_loss: 0.6010 - val_acc: 0.8541
Epoch 30/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6315 - acc: 0.8320 - val_loss: 0.6907 - val_acc: 0.8239
Epoch 31/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6289 - acc: 0.8331 - val_loss: 0.5946 - val_acc: 0.8537
Epoch 32/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6287 - acc: 0.8335 - val_loss: 0.6842 - val_acc: 0.8244
Epoch 33/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6259 - acc: 0.8348 - val_loss: 0.6518 - val_acc: 0.8327
Epoch 34/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6231 - acc: 0.8382 - val_loss: 0.6163 - val_acc: 0.8439
Epoch 35/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6239 - acc: 0.8350 - val_loss: 0.5705 - val_acc: 0.8571
Epoch 36/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6205 - acc: 0.8373 - val_loss: 0.6504 - val_acc: 0.8338
Epoch 37/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6148 - acc: 0.8384 - val_loss: 0.6141 - val_acc: 0.8485
Epoch 38/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6164 - acc: 0.8393 - val_loss: 0.6814 - val_acc: 0.8244
Epoch 39/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6160 - acc: 0.8391 - val_loss: 0.5827 - val_acc: 0.8536
Epoch 40/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6119 - acc: 0.8379 - val_loss: 0.6707 - val_acc: 0.8339
Epoch 41/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6132 - acc: 0.8385 - val_loss: 0.6569 - val_acc: 0.8347
Epoch 42/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6091 - acc: 0.8427 - val_loss: 0.6146 - val_acc: 0.8505
Epoch 43/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6079 - acc: 0.8416 - val_loss: 0.5889 - val_acc: 0.8534
Epoch 44/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6053 - acc: 0.8437 - val_loss: 0.5950 - val_acc: 0.8496
Epoch 45/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6073 - acc: 0.8425 - val_loss: 0.6484 - val_acc: 0.8363
Epoch 46/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6057 - acc: 0.8432 - val_loss: 0.5944 - val_acc: 0.8514
Epoch 47/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6013 - acc: 0.8443 - val_loss: 0.6132 - val_acc: 0.8457
Epoch 48/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5998 - acc: 0.8442 - val_loss: 0.6391 - val_acc: 0.8365
Epoch 49/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5968 - acc: 0.8470 - val_loss: 0.6204 - val_acc: 0.8485
Epoch 50/125
781/781 [==============================] - 16s 20ms/step - loss: 0.6012 - acc: 0.8454 - val_loss: 0.5619 - val_acc: 0.8626
Epoch 51/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5973 - acc: 0.8457 - val_loss: 0.6445 - val_acc: 0.8387
Epoch 52/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5996 - acc: 0.8448 - val_loss: 0.6063 - val_acc: 0.8507
Epoch 53/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5923 - acc: 0.8475 - val_loss: 0.6388 - val_acc: 0.8442
Epoch 54/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5938 - acc: 0.8486 - val_loss: 0.6168 - val_acc: 0.8445
Epoch 55/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5914 - acc: 0.8472 - val_loss: 0.5889 - val_acc: 0.8553
Epoch 56/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5944 - acc: 0.8491 - val_loss: 0.5931 - val_acc: 0.8536
Epoch 57/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5909 - acc: 0.8491 - val_loss: 0.6346 - val_acc: 0.8468
Epoch 58/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5905 - acc: 0.8498 - val_loss: 0.5594 - val_acc: 0.8623
Epoch 59/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5917 - acc: 0.8491 - val_loss: 0.6686 - val_acc: 0.8389
Epoch 60/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5887 - acc: 0.8502 - val_loss: 0.5982 - val_acc: 0.8512
Epoch 61/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5861 - acc: 0.8504 - val_loss: 0.6111 - val_acc: 0.8511
Epoch 62/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5892 - acc: 0.8494 - val_loss: 0.5981 - val_acc: 0.8505
Epoch 63/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5807 - acc: 0.8518 - val_loss: 0.5972 - val_acc: 0.8551
Epoch 64/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5845 - acc: 0.8506 - val_loss: 0.6228 - val_acc: 0.8486
Epoch 65/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5808 - acc: 0.8508 - val_loss: 0.6007 - val_acc: 0.8549
Epoch 66/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5875 - acc: 0.8509 - val_loss: 0.6119 - val_acc: 0.8544
Epoch 67/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5838 - acc: 0.8533 - val_loss: 0.5724 - val_acc: 0.8600
Epoch 68/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5806 - acc: 0.8507 - val_loss: 0.6136 - val_acc: 0.8529
Epoch 69/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5794 - acc: 0.8514 - val_loss: 0.5783 - val_acc: 0.8613
Epoch 70/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5808 - acc: 0.8526 - val_loss: 0.5798 - val_acc: 0.8653
Epoch 71/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5796 - acc: 0.8516 - val_loss: 0.6059 - val_acc: 0.8528
Epoch 72/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5766 - acc: 0.8536 - val_loss: 0.5885 - val_acc: 0.8556
Epoch 73/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5748 - acc: 0.8555 - val_loss: 0.6168 - val_acc: 0.8507
Epoch 74/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5805 - acc: 0.8533 - val_loss: 0.5968 - val_acc: 0.8573
Epoch 75/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5735 - acc: 0.8536 - val_loss: 0.6052 - val_acc: 0.8482
Epoch 76/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5755 - acc: 0.8550 - val_loss: 0.5928 - val_acc: 0.8538
Epoch 77/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5322 - acc: 0.8699 - val_loss: 0.5691 - val_acc: 0.8662
Epoch 78/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5134 - acc: 0.8735 - val_loss: 0.5137 - val_acc: 0.8784
Epoch 79/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5014 - acc: 0.8759 - val_loss: 0.4906 - val_acc: 0.8855
Epoch 80/125
781/781 [==============================] - 16s 20ms/step - loss: 0.5011 - acc: 0.8759 - val_loss: 0.5275 - val_acc: 0.8737
Epoch 81/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4928 - acc: 0.8775 - val_loss: 0.5270 - val_acc: 0.8720
Epoch 82/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4912 - acc: 0.8792 - val_loss: 0.4927 - val_acc: 0.8801
Epoch 83/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4841 - acc: 0.8799 - val_loss: 0.5228 - val_acc: 0.8742
Epoch 84/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4835 - acc: 0.8777 - val_loss: 0.5394 - val_acc: 0.8686
Epoch 85/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4835 - acc: 0.8777 - val_loss: 0.5337 - val_acc: 0.8738
Epoch 86/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4809 - acc: 0.8770 - val_loss: 0.5140 - val_acc: 0.8722
Epoch 87/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4764 - acc: 0.8796 - val_loss: 0.4666 - val_acc: 0.8890
Epoch 88/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4699 - acc: 0.8814 - val_loss: 0.5048 - val_acc: 0.8757
Epoch 89/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4727 - acc: 0.8797 - val_loss: 0.5375 - val_acc: 0.8722
Epoch 90/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4641 - acc: 0.8827 - val_loss: 0.4826 - val_acc: 0.8839
Epoch 91/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4668 - acc: 0.8817 - val_loss: 0.4945 - val_acc: 0.8801
Epoch 92/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4702 - acc: 0.8792 - val_loss: 0.5126 - val_acc: 0.8760
Epoch 93/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4617 - acc: 0.8813 - val_loss: 0.4658 - val_acc: 0.8860
Epoch 94/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4693 - acc: 0.8772 - val_loss: 0.5272 - val_acc: 0.8695
Epoch 95/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4593 - acc: 0.8826 - val_loss: 0.5258 - val_acc: 0.8675
Epoch 96/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4591 - acc: 0.8824 - val_loss: 0.4895 - val_acc: 0.8790
Epoch 97/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4613 - acc: 0.8822 - val_loss: 0.5204 - val_acc: 0.8716
Epoch 98/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4579 - acc: 0.8819 - val_loss: 0.4910 - val_acc: 0.8813
Epoch 99/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4584 - acc: 0.8804 - val_loss: 0.5160 - val_acc: 0.8740
Epoch 100/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4562 - acc: 0.8827 - val_loss: 0.4716 - val_acc: 0.8818
Epoch 101/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4556 - acc: 0.8833 - val_loss: 0.5070 - val_acc: 0.8709
Epoch 102/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4521 - acc: 0.8828 - val_loss: 0.5117 - val_acc: 0.8750
Epoch 103/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4618 - acc: 0.8795 - val_loss: 0.4934 - val_acc: 0.8767
Epoch 104/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4493 - acc: 0.8840 - val_loss: 0.4845 - val_acc: 0.8777
Epoch 105/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4531 - acc: 0.8842 - val_loss: 0.4585 - val_acc: 0.8840
Epoch 106/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4497 - acc: 0.8826 - val_loss: 0.4876 - val_acc: 0.8765
Epoch 107/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4520 - acc: 0.8839 - val_loss: 0.5005 - val_acc: 0.8721
Epoch 108/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4487 - acc: 0.8824 - val_loss: 0.5169 - val_acc: 0.8715
Epoch 109/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4503 - acc: 0.8843 - val_loss: 0.4759 - val_acc: 0.8843
Epoch 110/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4548 - acc: 0.8817 - val_loss: 0.4670 - val_acc: 0.8842
Epoch 111/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4406 - acc: 0.8850 - val_loss: 0.4878 - val_acc: 0.8801
Epoch 112/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4438 - acc: 0.8843 - val_loss: 0.4999 - val_acc: 0.8723
Epoch 113/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4481 - acc: 0.8828 - val_loss: 0.4576 - val_acc: 0.8914
Epoch 114/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4422 - acc: 0.8859 - val_loss: 0.4923 - val_acc: 0.8777
Epoch 115/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4461 - acc: 0.8840 - val_loss: 0.5143 - val_acc: 0.8700
Epoch 116/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4467 - acc: 0.8844 - val_loss: 0.5480 - val_acc: 0.8636
Epoch 117/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4478 - acc: 0.8832 - val_loss: 0.5200 - val_acc: 0.8705
Epoch 118/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4403 - acc: 0.8854 - val_loss: 0.4824 - val_acc: 0.8806
Epoch 119/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4428 - acc: 0.8845 - val_loss: 0.4998 - val_acc: 0.8745
Epoch 120/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4491 - acc: 0.8828 - val_loss: 0.5038 - val_acc: 0.8743
Epoch 121/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4377 - acc: 0.8866 - val_loss: 0.5081 - val_acc: 0.8747
Epoch 122/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4416 - acc: 0.8860 - val_loss: 0.5251 - val_acc: 0.8658
Epoch 123/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4424 - acc: 0.8851 - val_loss: 0.5023 - val_acc: 0.8760
Epoch 124/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4425 - acc: 0.8848 - val_loss: 0.4697 - val_acc: 0.8831
Epoch 125/125
781/781 [==============================] - 16s 20ms/step - loss: 0.4447 - acc: 0.8844 - val_loss: 0.4987 - val_acc: 0.8751
10000/10000 [==============================] - 1s 77us/step

Test result: 87.510 loss: 0.499

