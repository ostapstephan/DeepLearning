Using TensorFlow backend.
(32, 32, 3)
(40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)
Training features shape:  (40000, 32, 32, 3)
Validation features shape:  (10000, 32, 32, 3)
Test features shape:  (10000, 32, 32, 3)
hi (32, 32, 3)
(?, 32, 32, 3)
2018-10-03 23:01:03.555695: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-10-03 23:01:03.650806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-03 23:01:03.651249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785
pciBusID: 0000:01:00.0
totalMemory: 3.94GiB freeMemory: 3.04GiB
2018-10-03 23:01:03.717166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-03 23:01:03.717561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 1 with properties: 
name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.329
pciBusID: 0000:02:00.0
totalMemory: 3.94GiB freeMemory: 3.87GiB
2018-10-03 23:01:03.717714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0, 1
2018-10-03 23:01:04.075004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-03 23:01:04.075037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 1 
2018-10-03 23:01:04.075042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N Y 
2018-10-03 23:01:04.075045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   Y N 
2018-10-03 23:01:04.075239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2753 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0, compute capability: 5.2)
2018-10-03 23:01:04.097202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3599 MB memory) -> physical GPU (device: 1, name: GeForce GTX 970, pci bus id: 0000:02:00.0, compute capability: 5.2)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           conv2d_2[0][0]                   
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 16, 64)   9280        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 16, 16, 64)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 16, 16, 64)   36928       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 16, 16, 64)   0           conv2d_6[0][0]                   
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 16, 16, 64)   0           add_2[0][0]                      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 8, 8, 128)    512         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 8, 8, 128)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 8, 8, 128)    147584      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    147584      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 8, 8, 128)    0           conv2d_10[0][0]                  
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 8, 8, 128)    0           add_3[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 128)    0           activation_9[0][0]               
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 128)          0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           1290        dropout_1[0][0]                  
==================================================================================================
Total params: 461,034
Trainable params: 459,786
Non-trainable params: 1,248
__________________________________________________________________________________________________
Learning rate:  0.001
Epoch 1/128
1250/1250 [==============================] - 19s 16ms/step - loss: 1.5513 - acc: 0.4580 - val_loss: 1.4650 - val_acc: 0.5321
Epoch 2/128
1250/1250 [==============================] - 18s 14ms/step - loss: 1.2066 - acc: 0.5956 - val_loss: 1.2083 - val_acc: 0.5943
Epoch 3/128
1250/1250 [==============================] - 18s 14ms/step - loss: 1.0789 - acc: 0.6476 - val_loss: 1.2255 - val_acc: 0.6161
Epoch 4/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.9959 - acc: 0.6846 - val_loss: 1.0165 - val_acc: 0.6839
Epoch 5/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.9313 - acc: 0.7103 - val_loss: 0.9744 - val_acc: 0.6950
Epoch 6/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.8818 - acc: 0.7300 - val_loss: 0.8393 - val_acc: 0.7473
Epoch 7/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.8571 - acc: 0.7420 - val_loss: 0.9076 - val_acc: 0.7241
Epoch 8/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.8186 - acc: 0.7586 - val_loss: 0.7692 - val_acc: 0.7813
Epoch 9/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.8011 - acc: 0.7674 - val_loss: 0.8307 - val_acc: 0.7612
Epoch 10/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7797 - acc: 0.7752 - val_loss: 0.8364 - val_acc: 0.7555
Epoch 11/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7594 - acc: 0.7834 - val_loss: 0.8423 - val_acc: 0.7519
Epoch 12/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7442 - acc: 0.7918 - val_loss: 0.7740 - val_acc: 0.7861
Epoch 13/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7308 - acc: 0.7950 - val_loss: 0.7596 - val_acc: 0.7896
Epoch 14/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7172 - acc: 0.8017 - val_loss: 0.8352 - val_acc: 0.7708
Epoch 15/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.7081 - acc: 0.8051 - val_loss: 0.9306 - val_acc: 0.7544
Epoch 16/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6916 - acc: 0.8109 - val_loss: 0.8042 - val_acc: 0.7870
Epoch 17/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6874 - acc: 0.8137 - val_loss: 0.7342 - val_acc: 0.8000
Epoch 18/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6735 - acc: 0.8170 - val_loss: 0.8847 - val_acc: 0.7435
Epoch 19/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.6698 - acc: 0.8211 - val_loss: 0.9355 - val_acc: 0.7443
Epoch 20/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.6632 - acc: 0.8234 - val_loss: 0.8253 - val_acc: 0.7725
Epoch 21/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.6534 - acc: 0.8276 - val_loss: 0.7099 - val_acc: 0.8154
Epoch 22/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6480 - acc: 0.8310 - val_loss: 0.8086 - val_acc: 0.7907
Epoch 23/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6380 - acc: 0.8346 - val_loss: 0.7926 - val_acc: 0.7858
Epoch 24/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6357 - acc: 0.8354 - val_loss: 0.7458 - val_acc: 0.8079
Epoch 25/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6256 - acc: 0.8401 - val_loss: 0.7554 - val_acc: 0.8015
Epoch 26/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6241 - acc: 0.8399 - val_loss: 0.9385 - val_acc: 0.7703
Epoch 27/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6165 - acc: 0.8422 - val_loss: 0.6804 - val_acc: 0.8256
Epoch 28/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6077 - acc: 0.8460 - val_loss: 0.7670 - val_acc: 0.8112
Epoch 29/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6081 - acc: 0.8467 - val_loss: 0.8688 - val_acc: 0.7749
Epoch 30/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6020 - acc: 0.8487 - val_loss: 0.6479 - val_acc: 0.8382
Epoch 31/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.6004 - acc: 0.8498 - val_loss: 0.7547 - val_acc: 0.8065
Epoch 32/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5983 - acc: 0.8489 - val_loss: 0.7013 - val_acc: 0.8220
Epoch 33/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5976 - acc: 0.8532 - val_loss: 0.6950 - val_acc: 0.8256
Epoch 34/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5852 - acc: 0.8580 - val_loss: 1.0755 - val_acc: 0.7223
Epoch 35/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5853 - acc: 0.8553 - val_loss: 0.7187 - val_acc: 0.8237
Epoch 36/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5784 - acc: 0.8596 - val_loss: 0.7212 - val_acc: 0.8289
Epoch 37/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5753 - acc: 0.8601 - val_loss: 0.7197 - val_acc: 0.8183
Epoch 38/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5782 - acc: 0.8593 - val_loss: 0.7277 - val_acc: 0.8201
Epoch 39/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5701 - acc: 0.8622 - val_loss: 0.8036 - val_acc: 0.8079
Epoch 40/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.5652 - acc: 0.8628 - val_loss: 0.6151 - val_acc: 0.8510
Epoch 41/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5601 - acc: 0.8648 - val_loss: 0.6204 - val_acc: 0.8532
Epoch 42/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5615 - acc: 0.8656 - val_loss: 0.8412 - val_acc: 0.8038
Epoch 43/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5605 - acc: 0.8678 - val_loss: 0.6816 - val_acc: 0.8342
Epoch 44/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5589 - acc: 0.8666 - val_loss: 0.7836 - val_acc: 0.8176
Epoch 45/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5605 - acc: 0.8690 - val_loss: 0.8236 - val_acc: 0.8082
Epoch 46/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5526 - acc: 0.8698 - val_loss: 0.7410 - val_acc: 0.8245
Epoch 47/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5481 - acc: 0.8717 - val_loss: 0.7148 - val_acc: 0.8275
Epoch 48/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5438 - acc: 0.8721 - val_loss: 0.7068 - val_acc: 0.8273
Epoch 49/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5392 - acc: 0.8738 - val_loss: 0.7087 - val_acc: 0.8289
Epoch 50/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5436 - acc: 0.8745 - val_loss: 0.6733 - val_acc: 0.8350
Epoch 51/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5395 - acc: 0.8766 - val_loss: 0.9237 - val_acc: 0.7811
Epoch 52/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5400 - acc: 0.8737 - val_loss: 0.6227 - val_acc: 0.8610
Epoch 53/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5320 - acc: 0.8764 - val_loss: 0.6209 - val_acc: 0.8574
Epoch 54/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5377 - acc: 0.8774 - val_loss: 0.7283 - val_acc: 0.8244
Epoch 55/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5316 - acc: 0.8776 - val_loss: 1.0511 - val_acc: 0.7619
Epoch 56/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5353 - acc: 0.8772 - val_loss: 0.7133 - val_acc: 0.8251
Epoch 57/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5258 - acc: 0.8805 - val_loss: 0.7092 - val_acc: 0.8290
Epoch 58/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5283 - acc: 0.8796 - val_loss: 0.7363 - val_acc: 0.8148
Epoch 59/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5321 - acc: 0.8778 - val_loss: 0.7650 - val_acc: 0.8210
Epoch 60/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5210 - acc: 0.8825 - val_loss: 0.6857 - val_acc: 0.8436
Epoch 61/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5217 - acc: 0.8810 - val_loss: 0.7406 - val_acc: 0.8325
Epoch 62/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5250 - acc: 0.8805 - val_loss: 0.7293 - val_acc: 0.8323
Epoch 63/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5310 - acc: 0.8809 - val_loss: 0.6364 - val_acc: 0.8558
Epoch 64/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5190 - acc: 0.8836 - val_loss: 0.7392 - val_acc: 0.8258
Epoch 65/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5167 - acc: 0.8834 - val_loss: 0.6300 - val_acc: 0.8535
Epoch 66/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5209 - acc: 0.8827 - val_loss: 0.9843 - val_acc: 0.7631
Epoch 67/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5150 - acc: 0.8838 - val_loss: 1.1860 - val_acc: 0.7468
Epoch 68/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5145 - acc: 0.8854 - val_loss: 0.6620 - val_acc: 0.8485
Epoch 69/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5126 - acc: 0.8871 - val_loss: 0.8482 - val_acc: 0.8008
Epoch 70/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5164 - acc: 0.8854 - val_loss: 0.7956 - val_acc: 0.8157
Epoch 71/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5098 - acc: 0.8881 - val_loss: 0.8265 - val_acc: 0.8084
Epoch 72/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5133 - acc: 0.8865 - val_loss: 0.8421 - val_acc: 0.8134
Epoch 73/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5056 - acc: 0.8891 - val_loss: 1.0598 - val_acc: 0.7630
Epoch 74/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5124 - acc: 0.8870 - val_loss: 0.7725 - val_acc: 0.8258
Epoch 75/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5088 - acc: 0.8894 - val_loss: 0.6813 - val_acc: 0.8477
Epoch 76/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5106 - acc: 0.8861 - val_loss: 0.6505 - val_acc: 0.8508
Epoch 77/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5073 - acc: 0.8902 - val_loss: 0.6992 - val_acc: 0.8363
Epoch 78/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5034 - acc: 0.8901 - val_loss: 0.7195 - val_acc: 0.8386
Epoch 79/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5070 - acc: 0.8895 - val_loss: 0.6938 - val_acc: 0.8375
Epoch 80/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5113 - acc: 0.8891 - val_loss: 0.7473 - val_acc: 0.8297
Epoch 81/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5002 - acc: 0.8915 - val_loss: 0.7611 - val_acc: 0.8202
Epoch 82/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5039 - acc: 0.8899 - val_loss: 0.6681 - val_acc: 0.8416
Epoch 83/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5027 - acc: 0.8900 - val_loss: 0.6336 - val_acc: 0.8517
Epoch 84/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4983 - acc: 0.8916 - val_loss: 0.7194 - val_acc: 0.8302
Epoch 85/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.5002 - acc: 0.8923 - val_loss: 1.0029 - val_acc: 0.7852
Epoch 86/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4999 - acc: 0.8919 - val_loss: 0.8044 - val_acc: 0.8260
Epoch 87/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4966 - acc: 0.8931 - val_loss: 1.1566 - val_acc: 0.7432
Epoch 88/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4972 - acc: 0.8920 - val_loss: 0.8051 - val_acc: 0.8166
Epoch 89/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4972 - acc: 0.8932 - val_loss: 0.7141 - val_acc: 0.8425
Epoch 90/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4916 - acc: 0.8944 - val_loss: 0.7837 - val_acc: 0.8211
Epoch 91/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4933 - acc: 0.8956 - val_loss: 0.7798 - val_acc: 0.8243
Epoch 92/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4906 - acc: 0.8956 - val_loss: 1.0494 - val_acc: 0.7732
Epoch 93/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4938 - acc: 0.8945 - val_loss: 0.6994 - val_acc: 0.8341
Epoch 94/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4914 - acc: 0.8954 - val_loss: 0.7362 - val_acc: 0.8255
Epoch 95/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4909 - acc: 0.8962 - val_loss: 1.0351 - val_acc: 0.7753
Epoch 96/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4907 - acc: 0.8961 - val_loss: 0.8539 - val_acc: 0.8098
Epoch 97/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4860 - acc: 0.8959 - val_loss: 0.6508 - val_acc: 0.8520
Epoch 98/128
1250/1250 [==============================] - 19s 15ms/step - loss: 0.4910 - acc: 0.8962 - val_loss: 0.7675 - val_acc: 0.8220
Epoch 99/128
1250/1250 [==============================] - 18s 15ms/step - loss: 0.4889 - acc: 0.8962 - val_loss: 0.8593 - val_acc: 0.8055
Epoch 100/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4897 - acc: 0.8974 - val_loss: 0.9825 - val_acc: 0.7745
Epoch 101/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4896 - acc: 0.8962 - val_loss: 0.6957 - val_acc: 0.8437
Epoch 102/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4849 - acc: 0.8975 - val_loss: 0.7008 - val_acc: 0.8499
Epoch 103/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4927 - acc: 0.8956 - val_loss: 1.1211 - val_acc: 0.7807
Epoch 104/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4846 - acc: 0.8979 - val_loss: 0.8448 - val_acc: 0.8155
Epoch 105/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4901 - acc: 0.8963 - val_loss: 0.8069 - val_acc: 0.8265
Epoch 106/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4832 - acc: 0.8985 - val_loss: 0.8286 - val_acc: 0.8143
Epoch 107/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4881 - acc: 0.8980 - val_loss: 0.9377 - val_acc: 0.7984
Epoch 108/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4865 - acc: 0.8962 - val_loss: 0.7127 - val_acc: 0.8383
Epoch 109/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4824 - acc: 0.8981 - val_loss: 0.9387 - val_acc: 0.7860
Epoch 110/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4783 - acc: 0.8997 - val_loss: 0.7560 - val_acc: 0.8342
Epoch 111/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4833 - acc: 0.8980 - val_loss: 0.6630 - val_acc: 0.8561
Epoch 112/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4824 - acc: 0.8999 - val_loss: 0.6388 - val_acc: 0.8669
Epoch 113/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4809 - acc: 0.8993 - val_loss: 0.7886 - val_acc: 0.8301
Epoch 114/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4842 - acc: 0.8991 - val_loss: 0.8109 - val_acc: 0.8191
Epoch 115/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4805 - acc: 0.8991 - val_loss: 1.0108 - val_acc: 0.7870
Epoch 116/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4836 - acc: 0.8979 - val_loss: 0.8277 - val_acc: 0.8091
Epoch 117/128
1250/1250 [==============================] - 18s 14ms/step - loss: 0.4803 - acc: 0.9016 - val_loss: 0.6799 - val_acc: 0.8579
Epoch 118/128
1250/1250 [==============================] - 18s 15ms/step - loss: 0.4762 - acc: 0.9009 - val_loss: 0.8215 - val_acc: 0.8184
Epoch 119/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4785 - acc: 0.9007 - val_loss: 0.8481 - val_acc: 0.8249
Epoch 120/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4841 - acc: 0.8979 - val_loss: 0.8912 - val_acc: 0.8024
Epoch 121/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4767 - acc: 0.9023 - val_loss: 0.6764 - val_acc: 0.8463
Epoch 122/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4797 - acc: 0.8996 - val_loss: 0.7599 - val_acc: 0.8258
Epoch 123/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4810 - acc: 0.9005 - val_loss: 1.0583 - val_acc: 0.7755
Epoch 124/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4740 - acc: 0.9028 - val_loss: 0.7601 - val_acc: 0.8275
Epoch 125/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4785 - acc: 0.8999 - val_loss: 0.6896 - val_acc: 0.8445
Epoch 126/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4729 - acc: 0.9025 - val_loss: 0.8351 - val_acc: 0.8260
Epoch 127/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4741 - acc: 0.9025 - val_loss: 0.7246 - val_acc: 0.8423
Epoch 128/128
1250/1250 [==============================] - 17s 14ms/step - loss: 0.4809 - acc: 0.8992 - val_loss: 0.6616 - val_acc: 0.8470
10000/10000 [==============================] - 1s 130us/step
Test loss: 0.6819295300483703
Test accuracy: 0.847
